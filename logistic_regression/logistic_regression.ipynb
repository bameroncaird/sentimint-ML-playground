{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362470ff",
   "metadata": {},
   "source": [
    "In this notebook, we will try to get logistic regression running.\n",
    "\n",
    "Helpful documentation: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6ed54a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9010d83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38961, 2)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_path = \"cleaned_data.csv\" # get the data without the disagreements\n",
    "data = pd.read_csv(data_path)[['text','sentiment']]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7d117aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spent the entire morning in a meeting w/ a ven...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>says good (or should i say bad?) afternoon!  h...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>had an awsome salad! I recommend getting the S...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38956</th>\n",
       "      <td>RT @toricolelli: My phones been charging for a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38957</th>\n",
       "      <td>'@WhoaBiebz: GET YOUR SHIT TOGETHER OR I'LL GU...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38958</th>\n",
       "      <td>Those** PICK UP THE SLACK YOU FUCK BOYS @Apple</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38959</th>\n",
       "      <td>@umo_games @Apple ended up getting a new compu...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38960</th>\n",
       "      <td>The 19-Year-Old #WizKid Who Turned Down @Apple...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38961 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0      Spent the entire morning in a meeting w/ a ven...   neutral\n",
       "1          Oh! Good idea about putting them on ice cream  positive\n",
       "2      says good (or should i say bad?) afternoon!  h...   neutral\n",
       "3                 haha better drunken tweeting you mean?  positive\n",
       "4      had an awsome salad! I recommend getting the S...  positive\n",
       "...                                                  ...       ...\n",
       "38956  RT @toricolelli: My phones been charging for a...  negative\n",
       "38957  '@WhoaBiebz: GET YOUR SHIT TOGETHER OR I'LL GU...  negative\n",
       "38958     Those** PICK UP THE SLACK YOU FUCK BOYS @Apple  negative\n",
       "38959  @umo_games @Apple ended up getting a new compu...   neutral\n",
       "38960  The 19-Year-Old #WizKid Who Turned Down @Apple...   neutral\n",
       "\n",
       "[38961 rows x 2 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f9d74055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num pos = 11497\n",
      "num neg = 13604\n",
      "num neu = 13860\n",
      "num other = 0\n"
     ]
    }
   ],
   "source": [
    "# how many labels of each class?\n",
    "num_pos = 0; num_neg = 0; num_neu = 0; other = 0\n",
    "for index, row in data.iterrows():\n",
    "    label = row['sentiment']\n",
    "    if label == 'positive': num_pos += 1\n",
    "    elif label == 'negative': num_neg += 1\n",
    "    elif label == 'neutral': num_neu += 1\n",
    "    else: other += 1\n",
    "\n",
    "print(\"num pos = {}\".format(num_pos))\n",
    "print(\"num neg = {}\".format(num_neg))\n",
    "print(\"num neu = {}\".format(num_neu))\n",
    "print(\"num other = {}\".format(other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b99d5e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num pos = 10356\n",
      "num neg = 12208\n",
      "num neu = 12500\n",
      "num other = 0\n"
     ]
    }
   ],
   "source": [
    "# split into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.1)\n",
    "\n",
    "# how many labels of each class?\n",
    "num_pos = 0; num_neg = 0; num_neu = 0; other = 0\n",
    "for index, row in train.iterrows():\n",
    "    label = row['sentiment']\n",
    "    if label == 'positive': num_pos += 1\n",
    "    elif label == 'negative': num_neg += 1\n",
    "    elif label == 'neutral': num_neu += 1\n",
    "    else: other += 1\n",
    "\n",
    "print(\"num pos = {}\".format(num_pos))\n",
    "print(\"num neg = {}\".format(num_neg))\n",
    "print(\"num neu = {}\".format(num_neu))\n",
    "print(\"num other = {}\".format(other))\n",
    "\n",
    "# change labels to numbers (if you run this in another cell it breaks everything)\n",
    "train[\"sentiment\"] = train[\"sentiment\"].map({\"positive\": 0, \"negative\": 1, \"neutral\": 2})\n",
    "test[\"sentiment\"] = test[\"sentiment\"].map({\"positive\": 0, \"negative\": 1, \"neutral\": 2})\n",
    "\n",
    "# fill the NaN values with empty string\n",
    "train.fillna('',inplace=True)\n",
    "test.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "6fc49517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35064, 2) (3897, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25784</th>\n",
       "      <td>No. RT @JetBlue Our fleet's on fleek.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16611</th>\n",
       "      <td>rblpn   , You know, I could listen to every ve...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14301</th>\n",
       "      <td>Happy to have a Sunday off from work</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>I need a code</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20658</th>\n",
       "      <td>Happy Star Wars day!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8191</th>\n",
       "      <td>&amp;quot;i hear its wonderful in california.&amp;quot;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>Hey girl, yeah I did..thanks a bunch!! I have...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38000</th>\n",
       "      <td>@apple IOS8 is still shit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5958</th>\n",
       "      <td>Just started feeling bad again  ugh. I hate it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>Loving Lego Indiana Jones. A game-researching ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "25784              No. RT @JetBlue Our fleet's on fleek.          2\n",
       "16611  rblpn   , You know, I could listen to every ve...          2\n",
       "14301               Happy to have a Sunday off from work          0\n",
       "3767                                       I need a code          2\n",
       "20658                               Happy Star Wars day!          0\n",
       "...                                                  ...        ...\n",
       "8191     &quot;i hear its wonderful in california.&quot;          0\n",
       "4698    Hey girl, yeah I did..thanks a bunch!! I have...          0\n",
       "38000                          @apple IOS8 is still shit          1\n",
       "5958   Just started feeling bad again  ugh. I hate it...          1\n",
       "6738   Loving Lego Indiana Jones. A game-researching ...          0\n",
       "\n",
       "[35064 rows x 2 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape, test.shape)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "203575bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16673</th>\n",
       "      <td>The World is just amazing!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10216</th>\n",
       "      <td>So I was just angrily told I was extemely abus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26950</th>\n",
       "      <td>@JetBlue yes, well they are operating outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29275</th>\n",
       "      <td>@AmericanAir I had a 6am flight I can get no r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17752</th>\n",
       "      <td>The best I could do for proof of the crack  LO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7090</th>\n",
       "      <td>Wow one of the nicest patients I've ever had! ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25358</th>\n",
       "      <td>@SouthwestAir how are flights looking for tomo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35327</th>\n",
       "      <td>RT @larryelder: Trump should have said, \"Megyn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>is currently watching supernatural whilst wait...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>Still totally excited that my oldest friend  h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3897 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "16673                         The World is just amazing!          0\n",
       "10216  So I was just angrily told I was extemely abus...          1\n",
       "26950  @JetBlue yes, well they are operating outside ...          1\n",
       "29275  @AmericanAir I had a 6am flight I can get no r...          1\n",
       "17752  The best I could do for proof of the crack  LO...          0\n",
       "...                                                  ...        ...\n",
       "7090   Wow one of the nicest patients I've ever had! ...          0\n",
       "25358  @SouthwestAir how are flights looking for tomo...          2\n",
       "35327  RT @larryelder: Trump should have said, \"Megyn...          0\n",
       "565    is currently watching supernatural whilst wait...          2\n",
       "9058   Still totally excited that my oldest friend  h...          0\n",
       "\n",
       "[3897 rows x 2 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "363789cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35064, 35393)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train.text)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c283c827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no 22238\n",
      "rt 26964\n",
      "jetblue 17434\n",
      "our 23175\n",
      "fleet 13013\n"
     ]
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(count_vect.vocabulary_.items()):\n",
    "    if i < 5: print(k, v) # word & occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c97f7cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35064, 35393)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ce1e4d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35393,)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.idf_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "08cc8c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='newton-cg')"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='newton-cg')\n",
    "clf.fit(X=X_train_tfidf, y=train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "20cdc95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful function\n",
    "def get_preprocess(mode='train'):\n",
    "    if mode == 'train':\n",
    "        X_count_vect = count_vect.fit_transform(train.text)\n",
    "    else:\n",
    "        X_count_vect = count_vect.fit_transform(test.text)\n",
    "    X_tfidf = tfidf_transformer.fit_transform(X_count_vect)\n",
    "    return X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bff24374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3897, 8923)\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test???\n",
    "# looks like we have to do the count vectorizer first on whole data, then split, tthen tf-idf\n",
    "X_test_tfidf = get_preprocess(mode='test')\n",
    "print(X_test_tfidf.shape)\n",
    "# preds = clf.predict(X_test_tfidf)\n",
    "# type(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "65391088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numeric labels\n",
    "data[\"sentiment\"] = data[\"sentiment\"].map({\"positive\": 0, \"negative\": 1, \"neutral\": 2})\n",
    "\n",
    "# fill the NaN values with empty string\n",
    "data.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d28d677b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38961, 37798)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_counts = count_vect.fit_transform(data.text)\n",
    "X_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ac91619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(X_counts, data.sentiment, test_size=0.1)\n",
    "\n",
    "X_train_counts = split[0]; X_test_counts = split[1]\n",
    "y_train_labels = split[2]; y_test_labels = split[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fe0ad09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35064, 37798)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d730dcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3897, 37798)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)\n",
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "973b851b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='newton-cg')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='newton-cg')\n",
    "clf.fit(X=X_train_tfidf, y=y_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "dfb49def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(X_test_tfidf)\n",
    "type(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "54e780c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_test_labels = np.array(y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7610d3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(3897,) (3897,)\n",
      "[1 0 1 2 1] [0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# should be similar format\n",
    "print(type(preds), type(y_test_labels))\n",
    "print(preds.shape, y_test_labels.shape)\n",
    "print(preds[:5], y_test_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "be6942a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8083140877598153"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc\n",
    "np.mean(preds == y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "dab1ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label(label):\n",
    "    if label == '0': print(\"positive\")\n",
    "    elif label == '1': print(\"negative\")\n",
    "    else: print(\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b23dee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"the movie was excellent and one of the best movies I've ever seen.\"\n",
    "middle = count_vect.transform([input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "770ea3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepred = tfidf_transformer.transform(middle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "482c3a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(prepred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9dee257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()), # first do CountVectorizer\n",
    "    ('tfidf', TfidfTransformer()), # then tf-idf\n",
    "    ('clf', LogisticRegression(solver='newton-cg')), # then logistic regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "fa2337bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LogisticRegression(solver='newton-cg'))])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(train.text, train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "38ba8eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = text_clf.predict(test.text)\n",
    "type(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ecafcf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3897,)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "1ac1ac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_labels = np.array(test.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "179b752e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0] [0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(preds[:5], tst_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "77ce8cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8165255324608673"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(preds == tst_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "e5bc2b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.89      0.81      0.85      1141\n",
      "    negative       0.82      0.84      0.83      1396\n",
      "     neutral       0.76      0.80      0.78      1360\n",
      "\n",
      "    accuracy                           0.82      3897\n",
      "   macro avg       0.82      0.82      0.82      3897\n",
      "weighted avg       0.82      0.82      0.82      3897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(tst_labels, preds, target_names=['positive', 'negative', 'neutral']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4bb4467b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"the movie was fucking horrible and one of the worst movies I've ever seen.\"\n",
    "text_clf.predict([input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "aebbaca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the pipeline + grid search to find the best params\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__strip_accents': [None, 'ascii', 'unicode'],\n",
    "    'vect__lowercase': (True, False),\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "    'clf__C': [1.0, 0.75, 0.5, 0.25],\n",
    "    'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "# params = {\n",
    "#     'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#     'vect__lowercase': (True, False),\n",
    "#     'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "# }\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4f708c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(solver='newton-cg'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__C': [1.0, 0.75, 0.5, 0.25],\n",
       "                         'clf__penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
       "                         'clf__solver': ['newton-cg', 'lbfgs', 'liblinear',\n",
       "                                         'sag', 'saga'],\n",
       "                         'tfidf__norm': ['l1', 'l2'],\n",
       "                         'tfidf__use_idf': (True, False),\n",
       "                         'vect__lowercase': (True, False),\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'vect__strip_accents': [None, 'ascii', 'unicode']})"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b299b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to be able to save and load models\n",
    "# need the count Vectorizer, the tf-idf thingy, and the model\n",
    "# can we create a pipeline and save iti all?\n",
    "save_path = \"models/log_reg_pipeline.pkl\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
